{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install libpysal\n",
        "!pip install dgl\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "AtqPuRnHKPjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import building data\n",
        "df_building = pd.read_csv('Boston_building.csv')\n",
        "df_building.head()\n",
        "df_building = df_building.sample(frac=1)"
      ],
      "metadata": {
        "id": "2TrgBx81Kgqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct and save edges\n",
        "import libpysal\n",
        "loc=[]\n",
        "for lon,lat in zip(df_building['X'].tolist(),df_building['Y'].tolist()):\n",
        "  loc.append([lon,lat])\n",
        "loc\n",
        "\n",
        "kd = libpysal.cg.KDTree(np.array(loc))\n",
        "wnn2 = libpysal.weights.KNN(kd, 10) # '10' is a hyperparameter, referring to a building of interest is connected with nearest 10 buildings, which can be customised.\n",
        "df_edge = pd.DataFrame(wnn2.asymmetry(), columns=['Src','Dst'])\n",
        "df_edge.to_csv('edge.csv')"
      ],
      "metadata": {
        "id": "WE67hVG0Koa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dgl dataset\n",
        "import dgl\n",
        "from dgl.data import DGLDataset\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class MyDataset(DGLDataset):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='graph_data')\n",
        "\n",
        "    def process(self):\n",
        "        nodes_data = df_building\n",
        "        edges_data = df_edge\n",
        "\n",
        "        node_features = torch.from_numpy(nodes_data.iloc[:,15:24].to_numpy()).float() # customise the index\n",
        "\n",
        "        # # classification task\n",
        "        node_labels = torch.from_numpy(nodes_data['storey'].to_numpy()).float() # replace the name to conduct specific tasks\n",
        "        # # classification task\n",
        "        # node_labels = torch.from_numpy(nodes_data['type'].astype('category').cat.codes.to_numpy()).long()\n",
        "        edges_src = torch.from_numpy(edges_data['Src'].to_numpy())\n",
        "        edges_dst = torch.from_numpy(edges_data['Dst'].to_numpy())\n",
        "        print(edges_src)\n",
        "\n",
        "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
        "        self.graph.ndata['feat'] = node_features\n",
        "        self.graph.ndata['label'] = node_labels\n",
        "\n",
        "        n_nodes = nodes_data.shape[0]\n",
        "        n_train = int(n_nodes * 0.7) # split 70% of the dataset for training\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[:n_train] = True\n",
        "        test_mask[n_train:] = True\n",
        "        self.graph.ndata['train_mask'] = train_mask\n",
        "        self.graph.ndata['test_mask'] = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "dataset = MyDataset()\n",
        "graph = dataset[0]\n",
        "graph = dgl.add_self_loop(graph)\n",
        "graph"
      ],
      "metadata": {
        "id": "LovvKl5lK_uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using GraphSAGE algorithm to build convolution layers\n",
        "from torch.nn.modules import activation\n",
        "import dgl.nn as dglnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "m = nn.ReLU()\n",
        "class SAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='pool')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hid_feats, out_feats=256, aggregator_type='pool')\n",
        "        self.conv3 = dglnn.SAGEConv(\n",
        "            in_feats=256, out_feats=out_feats, aggregator_type='pool')\n",
        "        self.fc1 = nn.Linear(out_feats,512)\n",
        "        self.fc2 = nn.Linear(512,256)\n",
        "        self.fc3 = nn.Linear(256,128)\n",
        "        # for regression task (i.e. predicting building heights, storeys, etc.)\n",
        "        self.output = nn.Linear(128,1)\n",
        "        # # for classification task (i.e. predicting building type, age, etc.)\n",
        "        # self.output = nn.Linear(128,k) # # k corresponds to the number of clasified building characteristics\n",
        "\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = self.conv2(graph, h)\n",
        "        h = self.conv3(graph, h)\n",
        "        h = self.fc1(h)\n",
        "        h = self.fc2(h)\n",
        "        h = self.fc3(h)\n",
        "        h = self.output(h)\n",
        "        # # for classification task, adding the following line of code\n",
        "        # h = F.softmax(h, dim=1)\n",
        "\n",
        "        return h"
      ],
      "metadata": {
        "id": "DEyerK0lP0Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_features = graph.ndata['feat']\n",
        "node_labels = graph.ndata['label']\n",
        "train_mask = graph.ndata['train_mask']\n",
        "test_mask = graph.ndata['test_mask']\n",
        "n_features = node_features.shape[1]\n",
        "# # for regression task\n",
        "n_labels = node_labels.shape[0]\n",
        "# # for classification task\n",
        "# n_labels = int(node_labels.max().item()+1)"
      ],
      "metadata": {
        "id": "TIndIo6PT7Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics for regression task\n",
        "\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "def evaluate(model, graph, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        prediction, indices = torch.max(logits, dim=1)\n",
        "        # RMSE\n",
        "        rmse = mean_squared_error(prediction,labels,squared=False)\n",
        "        # MAE\n",
        "        # mae = mean_absolute_error(prediction,labels)\n",
        "\n",
        "        return rmse\n",
        "        # return mae"
      ],
      "metadata": {
        "id": "rFtkHCpwUNQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics for classification task\n",
        "\n",
        "def evaluate(model, graph, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)"
      ],
      "metadata": {
        "id": "mdXLuXusUm4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dgl.use_libxsmm(False)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "95TNxGflWztv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression task: trainning and model evaluation\n",
        "\n",
        "model = SAGE(in_feats=n_features, hid_feats=256, out_feats=1)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001) # learning rate can be customised in future studies\n",
        "\n",
        "best_test_rmse = float('inf')\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    logits = model(graph, node_features)\n",
        "    logits,indics = torch.max(logits, dim=1)\n",
        "    # # RMSE\n",
        "    loss = F.mse_loss(logits[train_mask], node_labels[train_mask])\n",
        "    train_rmse = evaluate(model, graph, node_features, node_labels, train_mask)\n",
        "    test_rmse = evaluate(model, graph, node_features, node_labels, test_mask)\n",
        "    # # MAE\n",
        "    # loss = F.l1_loss(logits[train_mask], node_labels[train_mask])\n",
        "    # train_mae = evaluate(model, graph, node_features, node_labels, train_mask)\n",
        "    # test_mae = evaluate(model, graph, node_features, node_labels, test_mask)\n",
        "\n",
        "\n",
        "    # Early stopping based on test RMSE/MAE\n",
        "    if test_rmse < best_test_rmse:\n",
        "      best_test_rmse = test_rmse\n",
        "      best_epoch = epoch\n",
        "      best_model = model.state_dict()\n",
        "    elif best_epoch + 20 < epoch:  # No improvement for 20 epochs\n",
        "      print(f\"Early stopping at epoch {best_epoch} with best test RMSE/MAE: {best_test_rmse}\")\n",
        "      model.load_state_dict(best_model)\n",
        "      break\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    print(f'Epoch {epoch}, Loss: {loss.item()}, Train RMSE: {train_rmse}, Test RMSE: {test_rmse}')"
      ],
      "metadata": {
        "id": "GDv4oypQXbIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save predicted building storeys\n",
        "\n",
        "logits = model(graph, node_features)\n",
        "prediction, indices = torch.max(logits, dim=1)\n",
        "prediction_sage = prediction.detach().numpy()\n",
        "df_prediction = pd.DataFrame(prediction_sage,columns=['predicted_storey'])\n",
        "df_result = pd.concat([df_building, df_prediction], axis=1)\n",
        "df_result.head()"
      ],
      "metadata": {
        "id": "5_-egsREc5sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification task: trainning and model evaluation\n",
        "\n",
        "model = SAGE(in_feats=n_features, hid_feats=256, out_feats=n_labels)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_test_acc = 0   # to keep track of the best test accuracy\n",
        "patience = 50       # number of epochs to wait for improvement before stopping\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    logits = model(graph, node_features)\n",
        "    pred = logits.argmax(1)\n",
        "    loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
        "    train_acc = (pred[train_mask] == node_labels[train_mask]).float().mean()\n",
        "    test_acc = (pred[test_mask] == node_labels[test_mask]).float().mean()\n",
        "\n",
        "    if test_acc > best_test_acc: # if there's an improvement in accuracy\n",
        "        best_test_acc = test_acc\n",
        "        best_model_state = model.state_dict()  # save the best model\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    if epochs_without_improvement == patience:\n",
        "        print(f\"Early stopping on epoch {epoch}. Best test accuracy was {best_test_acc}.\")\n",
        "        model.load_state_dict(best_model_state)  # load the best model\n",
        "        break\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    print('In epoch {}, loss: {:.5f}, train_acc: {:.5f}, test_acc: {:.5f}'.format(\n",
        "                epoch, loss, train_acc, test_acc))"
      ],
      "metadata": {
        "id": "rE8VuSY5a9NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating classification tasks with F1-score, Precision, Recall\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "F1_score = f1_score(node_labels[test_mask], pred[test_mask], average=\"weighted\")\n",
        "Precision = precision_score(node_labels[test_mask], pred[test_mask], average='weighted')\n",
        "Recall = recall_score(node_labels[test_mask], pred[test_mask], average='weighted')"
      ],
      "metadata": {
        "id": "BTRl0UgCcEov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save predicted classes of building characteristics\n",
        "\n",
        "node_labels_df = node_labels.detach().numpy()\n",
        "df_node_labels = pd.DataFrame(node_labels_df,columns=['truth_type'])\n",
        "prediction_sage = pred.detach().numpy()\n",
        "df_prediction_sage = pd.DataFrame(prediction_sage,columns=['predicted_type'])\n",
        "df_type = pd.concat([df_building,df_prediction_sage], axis=1)\n",
        "df_type.head()"
      ],
      "metadata": {
        "id": "UJqDSTGRfTj1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}